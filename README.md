
Arabic Web Scraping and NLP Pipeline
This project aims to scrape data from Arabic web sources pertaining to a specific domain using libraries like Scrapy and Beautiful Soup. The scraped data will be stored in a NoSQL database, specifically MongoDB, for efficient storage and retrieval.

Usage Instructions:
Web Scraping:

Utilize Scrapy and Beautiful Soup libraries to scrape data from Arabic web sources relevant to the specified domain.
Data Storage:

Store the raw data in MongoDB to ensure scalability and flexibility in handling the scraped information.
NLP Pipeline:

Establish an NLP pipeline comprising text cleaning, tokenization, removal of stop words, discretization, and normalization to preprocess the scraped text data.
Stemming and Lemmatization:

Implement both stemming and lemmatization techniques to analyze the text data, and compare their effectiveness in the Arabic language context.
Parts of Speech Techniques:

Apply parts of speech (POS) tagging using both rule-based and machine learning approaches to categorize words in the text data based on their grammatical roles.
Named Entity Recognition (NER):

Employ NER methods to identify and extract named entities such as names of people, organizations, locations, etc., from the text data.
